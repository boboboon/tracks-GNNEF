{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL8Yu-kuemZg"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import namedtuple\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################TRACK CONSTRUCTION PROCESS########################\n",
        "def track_accuracy(pred_track, truth_track):\n",
        "  truths = []\n",
        "  for i in range(len(pred_track)):\n",
        "    for j in range (len(truth_track)):\n",
        "      is_a_track = np.array_equal(pred_track[i] , truth_track[j], equal_nan=False)\n",
        "      if is_a_track:\n",
        "        truths.append(i)\n",
        "        break\n",
        "  acc = len(truths)/ len(truth_track)\n",
        "  return acc, truths\n",
        "def construct_graph(ids_array): \n",
        "  t0 = time.time()\n",
        "  segment = ids_array.copy()\n",
        "  graphs = []\n",
        "  while len(segment) > 0:\n",
        "    segment_list =[]\n",
        "    no_more_conn = []\n",
        "    for elem in segment:\n",
        "      idx = np.where(ids_array[:,0] == elem[-1])\n",
        "      connections = ids_array[idx]\n",
        "      if len(connections) > 0:\n",
        "        for conenction in connections:\n",
        "          segment_list.append(np.unique(np.concatenate((elem,conenction))))\n",
        "      else:\n",
        "        no_more_conn.append(elem)\n",
        "      \n",
        "      segment = np.array(segment_list)\n",
        "    graphs.append(np.array(no_more_conn))\n",
        "  \n",
        "  return graphs"
      ],
      "metadata": {
        "id": "MldfkXPAe-LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########COMPARISION LISTS###############\n",
        "acc_seg = []\n",
        "times_pred_seg = []\n",
        "acc_track = []\n",
        "times_pred_track = []\n",
        "\n",
        "\n",
        "#########READ FILES################\n",
        "for sec in range(8):\n",
        "  df = pd.read_csv(f'/PATH_TO/GRAPH_BALANCED/Section_{sec}/event0.csv')\n",
        "\n",
        "  #TRAINING\n",
        "  for i in range(0,60):\n",
        "    \n",
        "    df2 = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/GRAPH_BALANCED/Section_{sec}/event{i}.csv')\n",
        "    new_ids = np.arange(max(df.hit_id_2)+1,max(df.hit_id_2)+ max(df2.hit_id_2)+2)\n",
        "    old_ids = np.arange(len(new_ids))\n",
        "    new_h1 = []\n",
        "    new_h2 = []\n",
        "    for value in df2.hit_id_1.values:\n",
        "        new_h1.append((new_ids[value]))\n",
        "    for value in df2.hit_id_2.values:\n",
        "        new_h2.append((new_ids[value]))\n",
        "    df2['hit_id_1'] = new_h1\n",
        "    df2['hit_id_2'] = new_h2\n",
        "    df = pd.concat([df, df2])\n",
        "\n",
        "\n",
        "  X_train = df[[ 'r_1', 'phi_1', 'z_1', 'ita_1','x_1','y_1','r_2', 'phi_2', 'z_2', 'ita_2','x_2','y_2','dphi', 'dz', 'dr', 'dita', 'dR','phi_slope', 'z0']]\n",
        "  y_train = df.y\n",
        "\n",
        "  #TESTING\n",
        "  df = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/GRAPH_BALANCED/Section_{sec}/event0.csv')\n",
        "  for i in range(60,90):\n",
        "    \n",
        "    df2 = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/GRAPH_BALANCED/Section_{sec}/event{i}.csv')\n",
        "    new_ids = np.arange(max(df.hit_id_2)+1,max(df.hit_id_2)+ max(df2.hit_id_2)+2)\n",
        "    old_ids = np.arange(len(new_ids))\n",
        "    new_h1 = []\n",
        "    new_h2 = []\n",
        "    for value in df2.hit_id_1.values:\n",
        "        new_h1.append((new_ids[value]))\n",
        "    for value in df2.hit_id_2.values:\n",
        "        new_h2.append((new_ids[value]))\n",
        "    df2['hit_id_1'] = new_h1\n",
        "    df2['hit_id_2'] = new_h2\n",
        "    df = pd.concat([df, df2])\n",
        "\n",
        "  X_test = df[[ 'r_1', 'phi_1', 'z_1', 'ita_1','x_1','y_1','r_2', 'phi_2', 'z_2', 'ita_2','x_2','y_2','dphi', 'dz', 'dr', 'dita', 'dR','phi_slope', 'z0']]\n",
        "  y_test = df.y\n",
        "  \n",
        "  ##############################XBG MODEL##############################################################\n",
        "  \n",
        "  model = MLPClassifier(hidden_layer_sizes=(15,15), random_state=1, max_iter= 200)\n",
        "  \n",
        "  model.fit(X_train, y_train)\n",
        " \n",
        "  t0 = time.time()\n",
        "  y_pred = model.predict(X_test)\n",
        "  times_pred_seg.append(time.time()-t0)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  acc_seg.append(accuracy)\n",
        "\n",
        "\n",
        "########################BUIL TRACK####################################################################\n",
        "  true_segments = df[['hit_id_1','hit_id_2']].iloc[np.where(y_test==True)].to_numpy()\n",
        "  pred_segments = df[['hit_id_1','hit_id_2']].iloc[np.where(y_pred==True)].to_numpy()\n",
        "  times_list =[]\n",
        "  acc_list=[]\n",
        "  time_graph = []\n",
        "    \n",
        "  true_tracks = construct_graph(true_segments)\n",
        "  pred_tracks = construct_graph(pred_segments)\n",
        "      \n",
        "      \n",
        "  accuracies = np.zeros(len(pred_tracks))\n",
        "  correct_idx  = []\n",
        "  predicted = np.zeros(len(pred_tracks))\n",
        "  truth = np.zeros(len(pred_tracks))\n",
        "  edge = np.zeros(len(pred_tracks))\n",
        "  correct = np.zeros(len(pred_tracks))\n",
        "  for i in range(len(pred_tracks)):\n",
        "    predicted[i] = len(pred_tracks[i])\n",
        "    truth[i] = len(true_tracks[i])\n",
        "    edge[i] = i + 1\n",
        "    acc, truths = track_accuracy(pred_tracks[i], true_tracks[i])\n",
        "            \n",
        "    correct[i] = len(truths)\n",
        "    accuracies[i] = acc  \n",
        "    correct_idx.append(truths)\n",
        "  acc_track.append(accuracies[2:])     \n",
        " "
      ],
      "metadata": {
        "id": "1-mpXHOxfAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(np.array(acc_track).flatten()), np.std(np.array(acc_track).flatten()), np.mean(times_pred_seg), np.std(times_pred_seg))"
      ],
      "metadata": {
        "id": "CB2NLqCzfJHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}